# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
Dataset is a collection of costumer information, such as marital status, job, education university degree ect. The problem is a classification problem and the aim is to predict if a given costumer is a "success" (class 1) or not (class 0).

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
Performance of hypertuning 
- using HyperDrive: accuracy score = 0.9073 (--C 0.4293569302394982 --max_iter 130)
- AutMl: accuracy score = 0.91502 (MaxAbsScaler, XGBoostClassifier)
 

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
**What are the benefits of the parameter sampler you chose?**
**What are the benefits of the early stopping policy you chose?**

The script train.py 

- loads the data into a TabularDatasetFactory dataset, 
- cleans the data (i.e. handles missing values by dropping them, one-hot encodes categorical features and loads the data into pandas DataFrame)
- splits the into features and target, 
- splits the features and target  into train and test 
- applies a logistic regression model to fit the training data and computes the accuracy for the test data,
- saves the model in the folder "./outputs/".

The logistic regression is a predictive analysis and it is used to describe data and to explain the relationship between te target variable "success or not" and the other independent variables, e.g. "marital status", "occupation", education university degree, ect. There are two hyperparameters for the logistic regression model: the inverse of regularization strength (C) and max iteration number (max_iter). The aim is to tune those hyperparameters using HyperDrive. 

To apply HyperDrive to the logistic regression model, we need to initialize the HyperDriveConfig class. To do so, we need to specify:

- Hyperparameter space: *RandomParameterSampling* defines a random sampling over the hyperparameter search spaces for C and max_iter. An advantages of randomly sampling from the spaces  include its simplicity and lack of bias.
- Early termination policy: *BanditPolicy* defines an early termination policy based on slack criteria and a frequency interval for evaluation.  An advantage of including an early termination policy is that we avoid overfitting during training. 
- An estimator that will be called with sampled hyperparameters:  SKLearn creates an estimator for training in Scikit-learn experiments (logistic regression model is importet from Scikit-learn); here we also specify the compute target to be used.
- Primary metric name and goal: The name of the primary metric reported by the experiment runs (*accuracy*) and if we wish to maximize or minimize the primary metric (maximize). 
- Max total runs and max concurrent runs : The maximum total number of runs to create and the maximum number of runs to execute concurrently. Note: the number of concurrent runs is gated on the resources available in the specified compute target. Hence ,we need to ensure that the compute target has the available resources for the desired concurrency.

Next we submit the hyperdrive run to the experiment (i.e. launch an experiment) and show run details with the RunDeatails widget. We collect and safe the best model, that is, the model with the tuned hyperparameters which yield the best accuracy score. 


## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
To apply AutoML we need to:

- load the data into a TabularDatasetFactory dataset, 
- prepare the data: here we can use a function from train.py to clean the data (as described here above), which returns features and target as a pandas DataFrame and Series, respectively
- concentate features and target into one DataFrame,
- split into train / test (or choose *n_cross_validation* when initializing AutoMLConfig)
- get data in TabularDataset form, 
- initiate AutoMLConfig class*,  
- submit the AutoMLConfig run to the experiment (i.e. launch an experiment) and show run details with the RunDeatails widget 
-  collect and safe the best model. 

* To initiate the AutoMLConfig class we need to specify: experiment_timeout_minutes, task, primary_metric, training_data, (validation_data or n_cross_validation), label_column_name, compute_target. 

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
Both for applying HyperDrive and AutoML we need to create a workspace, initiate an experiment, load the data and clean / prepare it. The difference between the two methods is that HyperDrive requires "more coding", meaning:
- we must have a custom-coded machine learning model, such as logistic regression, otherwise, HyperDrive will not know what model to optimize the parameters for,
- we need to specify the parameter search space, 
- define the sampling method over the search space, 
- specify the primary metric to optimize,
- define an early termination policy 
All those steps are not necessary when applying AutoML, i.e. AutoML does it for us. 

AutoML has a slighty better accuracy score the HyperDrive. This difference might be because another model was fitted when using AutoML, there was a bigger option of choosing a model.
